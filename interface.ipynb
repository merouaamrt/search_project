{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "733ce6f4-4de2-4e7a-9380-711a54a5913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Corpus chargÃ© : 15 documents, 21 auteurs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6e09ea3a4b4392b4f8cf5ea83c1b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n    <h2>Exploration dâ€™un corpus â€“ Intelligence Artificielle</h2>\\n    <p>\\n      â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ============================================================\n",
    "# PROJET FINAL TD8 / TD9 / TD10\n",
    "# Interface complÃ¨te sur corpus IA\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "\n",
    "from Corpus import Corpus\n",
    "from SearchEngine import SearchEngine\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Chargement du corpus\n",
    "# ============================================================\n",
    "\n",
    "corpus = Corpus.load(\"data/corpus.csv\")\n",
    "engine = SearchEngine(corpus)\n",
    "\n",
    "\n",
    "rows = []\n",
    "for doc_id, doc in corpus.id2doc.items():\n",
    "    rows.append({\n",
    "        \"id\": doc_id,\n",
    "        \"auteur\": getattr(doc, \"auteur\", \"inconnu\"),\n",
    "        \"source\": str(getattr(doc, \"source\", \"autre\")),\n",
    "        \"titre\": getattr(doc, \"titre\", \"\"),\n",
    "        \"texte\": getattr(doc, \"texte\", \"\"),\n",
    "        \"date\": getattr(doc, \"date\", None)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Dates propres\n",
    "df[\"date_dt\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Nettoyage des sources\n",
    "# ============================================================\n",
    "\n",
    "def normalize_source(s):\n",
    "    s = s.lower()\n",
    "    if \"reddit\" in s:\n",
    "        return \"Reddit\"\n",
    "    if \"arxiv\" in s:\n",
    "        return \"Arxiv\"\n",
    "    return \"Autre\"\n",
    "\n",
    "df[\"source\"] = df[\"source\"].apply(normalize_source)\n",
    "sources = sorted(df[\"source\"].unique())\n",
    "\n",
    "\n",
    "header = widgets.HTML(\n",
    "    f\"\"\"\n",
    "    <h2>Exploration dâ€™un corpus â€“ Intelligence Artificielle</h2>\n",
    "    <p>\n",
    "        Documents : <b>{len(df)}</b> |\n",
    "        Auteurs : <b>{df[\"auteur\"].nunique()}</b> |\n",
    "        Sources : <b>{\", \".join(sources)}</b>\n",
    "    </p>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# OUTILS TEXTE\n",
    "# ============================================================\n",
    "\n",
    "def tokenize(txt):\n",
    "    return [w.lower() for w in txt.split() if w.isalpha()]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONGLET 0 â€” Statistiques globales\n",
    "# ============================================================\n",
    "\n",
    "out_stats = widgets.Output()\n",
    "\n",
    "with out_stats:\n",
    "    display(\n",
    "        pd.DataFrame({\n",
    "            \"Documents\": df.groupby(\"source\").size(),\n",
    "            \"Auteurs\": df.groupby(\"source\")[\"auteur\"].nunique()\n",
    "        })\n",
    "    )\n",
    "\n",
    "tab_stats = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Statistiques globales</h3>\"),\n",
    "    out_stats\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONGLET 1 â€” Recherche\n",
    "# ============================================================\n",
    "\n",
    "query = widgets.Text(description=\"RequÃªte\")\n",
    "topk = widgets.IntSlider(value=10, min=1, max=30, description=\"Top\")\n",
    "\n",
    "src_filter = widgets.Dropdown(options=[\"(tous)\"] + sources, description=\"Source\")\n",
    "auth_filter = widgets.Dropdown(options=[\"(tous)\"], description=\"Auteur\")\n",
    "\n",
    "btn_search = widgets.Button(description=\"Rechercher\", button_style=\"primary\")\n",
    "out_search = widgets.Output()\n",
    "\n",
    "def update_authors(_=None):\n",
    "    if src_filter.value == \"(tous)\":\n",
    "        sub = df\n",
    "    else:\n",
    "        sub = df[df[\"source\"] == src_filter.value]\n",
    "    auth_filter.options = [\"(tous)\"] + sorted(sub[\"auteur\"].unique())\n",
    "\n",
    "src_filter.observe(update_authors, names=\"value\")\n",
    "update_authors()\n",
    "def run_search(_=None):\n",
    "    with out_search:\n",
    "        out_search.clear_output()\n",
    "\n",
    "        q = query.value.strip()\n",
    "        if not q:\n",
    "            print(\"Veuillez entrer une requÃªte.\")\n",
    "            return\n",
    "\n",
    "        # 1) SÃ©curiser l'appel au moteur\n",
    "        try:\n",
    "            res = engine.search(q, int(topk.value))\n",
    "        except Exception:\n",
    "            print(\"RequÃªte invalide ou erreur dans le moteur de recherche.\")\n",
    "            return\n",
    "\n",
    "        # 2) Si le moteur renvoie None / pas un DataFrame / vide\n",
    "        if res is None or not isinstance(res, pd.DataFrame) or res.empty:\n",
    "            print(\"Aucun rÃ©sultat.\")\n",
    "            return\n",
    "\n",
    "        # 3) Si la colonne id n'existe pas, on n'essaie pas de merge\n",
    "        if \"id\" not in res.columns:\n",
    "            print(\"Aucun rÃ©sultat.\")\n",
    "            return\n",
    "\n",
    "        # 4) Merge sÃ©curisÃ©\n",
    "        try:\n",
    "            res = res.merge(df[[\"id\", \"auteur\", \"source\"]], on=\"id\", how=\"left\")\n",
    "        except Exception:\n",
    "            print(\"Aucun rÃ©sultat.\")\n",
    "            return\n",
    "\n",
    "        # Nettoyage colonnes (inchangÃ©)\n",
    "        res = res.drop(columns=[c for c in res.columns if c.endswith(\"_x\")], errors=\"ignore\")\n",
    "        res = res.rename(columns={\"auteur_y\": \"auteur\"})\n",
    "\n",
    "        # Filtres (inchangÃ©s)\n",
    "        if src_filter.value != \"(tous)\":\n",
    "            res = res[res[\"source\"] == src_filter.value]\n",
    "\n",
    "        if auth_filter.value != \"(tous)\":\n",
    "            res = res[res[\"auteur\"] == auth_filter.value]\n",
    "\n",
    "        if res.empty:\n",
    "            print(\"Aucun rÃ©sultat.\")\n",
    "            return\n",
    "\n",
    "        # Affichage (inchangÃ©)\n",
    "        display(res[[\"score\", \"id\", \"titre\", \"auteur\", \"source\"]])\n",
    "\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.bar(range(len(res)), res[\"score\"])\n",
    "        plt.xlabel(\"RÃ©sultats\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.title(\"Scores des documents\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "btn_search.on_click(run_search)\n",
    "\n",
    "tab_search = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Recherche par mots-clÃ©s</h3>\"),\n",
    "    query, topk, src_filter, auth_filter,\n",
    "    btn_search, out_search\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONGLET 2 â€” Comparaison Reddit / Arxiv \n",
    "# ============================================================\n",
    "\n",
    "srcA = widgets.Dropdown(options=sources, description=\"Source A\")\n",
    "srcB = widgets.Dropdown(options=sources, description=\"Source B\")\n",
    "top_words = widgets.IntSlider(value=20, min=5, max=50, step=5, description=\"Top mots\")\n",
    "\n",
    "btn_cmp = widgets.Button(description=\"Comparer\", button_style=\"primary\")\n",
    "out_cmp = widgets.Output()\n",
    "\n",
    "def comparer_sources(dfA, dfB, top):\n",
    "    fA, fB = Counter(), Counter()\n",
    "    for t in dfA[\"texte\"]:\n",
    "        fA.update(tokenize(t))\n",
    "    for t in dfB[\"texte\"]:\n",
    "        fB.update(tokenize(t))\n",
    "\n",
    "    mots = set(fA) | set(fB)\n",
    "    rows = []\n",
    "\n",
    "    for m in mots:\n",
    "        rows.append({\n",
    "            \"mot\": m,\n",
    "            f\"{srcA.value}_freq\": fA.get(m, 0),\n",
    "            f\"{srcB.value}_freq\": fB.get(m, 0),\n",
    "            \"diff\": fA.get(m, 0) - fB.get(m, 0)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"diff\", ascending=False).head(top)\n",
    "\n",
    "#calcul TF/DF global \n",
    "def compute_global_tf_df():\n",
    "    tf = Counter()\n",
    "    dfreq = Counter()\n",
    "    for t in df[\"texte\"]:\n",
    "        toks = tokenize(t)\n",
    "        tf.update(toks)\n",
    "        dfreq.update(set(toks))\n",
    "    rows = [{\"mot\": m, \"TF\": tf[m], \"DF\": dfreq[m]} for m in tf.keys()]\n",
    "    return pd.DataFrame(rows).sort_values(\"TF\", ascending=False)\n",
    "\n",
    "# PrÃ©-calcul une seule fois \n",
    "GLOBAL_TF_DF = compute_global_tf_df()\n",
    "\n",
    "def run_cmp(_=None):\n",
    "    with out_cmp:\n",
    "        out_cmp.clear_output()\n",
    "\n",
    "        if srcA.value == srcB.value:\n",
    "            print(\"Choisissez deux sources diffÃ©rentes.\")\n",
    "            return\n",
    "\n",
    "        # Comparaison existante (inchangÃ©e)\n",
    "        display(\n",
    "            comparer_sources(\n",
    "                df[df[\"source\"] == srcA.value],\n",
    "                df[df[\"source\"] == srcB.value],\n",
    "                int(top_words.value)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Ajout TF/DF global \n",
    "        display(widgets.HTML(\"<b>Top mots globaux (TF / DF)</b>\"))\n",
    "        display(GLOBAL_TF_DF.head(15))\n",
    "\n",
    "btn_cmp.on_click(run_cmp)\n",
    "\n",
    "tab_cmp = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Comparaison lexicale Reddit / Arxiv</h3>\"),\n",
    "    srcA, srcB, top_words,\n",
    "    btn_cmp, out_cmp\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONGLET 3 â€” Ã‰volution temporelle\n",
    "# ============================================================\n",
    "\n",
    "mot_time = widgets.Text(\n",
    "    description=\"Mot\",\n",
    "    placeholder=\"ex : intelligence\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "date_start = widgets.DatePicker(\n",
    "    description=\"DÃ©but\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "date_end = widgets.DatePicker(\n",
    "    description=\"Fin\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "src_time = widgets.Dropdown(\n",
    "    options=[\"(tous)\"] + sources,\n",
    "    description=\"Source\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "btn_time = widgets.Button(\n",
    "    description=\"Afficher\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "\n",
    "out_time = widgets.Output()\n",
    "\n",
    "\n",
    "def run_time(_=None):\n",
    "    with out_time:\n",
    "        out_time.clear_output()\n",
    "\n",
    "        #sÃ©curitÃ© entrÃ©e utilisateur\n",
    "        mot = mot_time.value.lower().strip()\n",
    "        if mot == \"\":\n",
    "            print(\"Veuillez entrer un mot.\")\n",
    "            return\n",
    "\n",
    "        #copie du dataframe\n",
    "        dfx = df.copy()\n",
    "\n",
    "        # gestion des dates\n",
    "        dfx[\"date_dt\"] = pd.to_datetime(dfx[\"date\"], errors=\"coerce\", utc=True)\n",
    "        dfx[\"date_dt\"] = dfx[\"date_dt\"].dt.tz_convert(None)\n",
    "\n",
    "        dfx = dfx.dropna(subset=[\"date_dt\"])\n",
    "\n",
    "        # filtres\n",
    "        if src_time.value != \"(tous)\":\n",
    "            dfx = dfx[dfx[\"source\"] == src_time.value]\n",
    "\n",
    "        if date_start.value:\n",
    "            dfx = dfx[dfx[\"date_dt\"] >= pd.Timestamp(date_start.value)]\n",
    "\n",
    "        if date_end.value:\n",
    "            dfx = dfx[dfx[\"date_dt\"] <= pd.Timestamp(date_end.value)]\n",
    "\n",
    "        if dfx.empty:\n",
    "            print(\"Aucune donnÃ©e pour ces filtres.\")\n",
    "            return\n",
    "\n",
    "        # -comptage du mot\n",
    "        dfx[\"count\"] = dfx[\"texte\"].apply(lambda t: tokenize(t).count(mot))\n",
    "        dfx[\"year\"] = dfx[\"date_dt\"].dt.year\n",
    "\n",
    "        df_time = (\n",
    "            dfx.groupby(\"year\")[\"count\"]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(columns={\"year\": \"AnnÃ©e\", \"count\": \"FrÃ©quence\"})\n",
    "        )\n",
    "\n",
    "        if df_time[\"FrÃ©quence\"].sum() == 0:\n",
    "            print(f\"Le mot '{mot}' n'apparaÃ®t pas sur cette pÃ©riode.\")\n",
    "            return\n",
    "\n",
    "        display(df_time)\n",
    "\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.bar(df_time[\"AnnÃ©e\"], df_time[\"FrÃ©quence\"])\n",
    "        plt.xlabel(\"AnnÃ©e\")\n",
    "        plt.ylabel(\"Nombre d'occurrences\")\n",
    "        plt.title(f\"Ã‰volution du mot '{mot}'\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "        total = int(df_time[\"FrÃ©quence\"].sum())\n",
    "        pic = df_time.loc[df_time[\"FrÃ©quence\"].idxmax()]\n",
    "\n",
    "        print(\n",
    "            f\"Analyse automatique :\\n\"\n",
    "            f\"Le mot '{mot}' apparaÃ®t {total} fois sur la pÃ©riode sÃ©lectionnÃ©e.\\n\"\n",
    "            f\"Le pic d'utilisation est observÃ© en {int(pic['AnnÃ©e'])} \"\n",
    "            f\"avec {int(pic['FrÃ©quence'])} occurrences.\"\n",
    "        )\n",
    "\n",
    "\n",
    "btn_time.on_click(run_time)\n",
    "\n",
    "tab_time = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Ã‰volution temporelle dâ€™un mot</h3>\"),\n",
    "    mot_time,\n",
    "    widgets.HBox([date_start, date_end]),\n",
    "    src_time,\n",
    "    btn_time,\n",
    "    out_time\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ONGLET 4 â€” Exploration par auteur\n",
    "# ============================================================\n",
    "\n",
    "auth_select = widgets.Dropdown(\n",
    "    options=sorted(df[\"auteur\"].unique()),\n",
    "    description=\"Auteur\"\n",
    ")\n",
    "\n",
    "out_auth = widgets.Output()\n",
    "\n",
    "def show_author(_=None):\n",
    "    with out_auth:\n",
    "        out_auth.clear_output()\n",
    "        sub = df[df[\"auteur\"] == auth_select.value]\n",
    "        print(f\"Documents : {len(sub)}\")\n",
    "        display(sub[[\"titre\", \"source\", \"date\"]].head(10))\n",
    "\n",
    "auth_select.observe(show_author, names=\"value\")\n",
    "show_author()\n",
    "\n",
    "tab_auth = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Exploration par auteur</h3>\"),\n",
    "    auth_select, out_auth\n",
    "])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# AFFICHAGE FINAL\n",
    "# ============================================================\n",
    "\n",
    "tabs = widgets.Tab(children=[\n",
    "    tab_stats,\n",
    "    tab_search,\n",
    "    tab_cmp,\n",
    "    tab_time,\n",
    "    tab_auth\n",
    "])\n",
    "\n",
    "tabs.set_title(0, \"Stats\")\n",
    "tabs.set_title(1, \"Recherche\")\n",
    "tabs.set_title(2, \"Comparaison\")\n",
    "tabs.set_title(3, \"Temps\")\n",
    "tabs.set_title(4, \"Auteurs\")\n",
    "\n",
    "display(widgets.VBox([header, tabs]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "93ab820c-a84b-4deb-a279-92c2f6459213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af6017-a0a3-4e56-b134-af3a99b0479c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
